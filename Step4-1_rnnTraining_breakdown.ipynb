{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a1a2365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This notebook trains a single RNN using all ten sessions of data and a specified train/test partition\n",
    "#(can be 'HeldOutBlocks' or 'HeldOutTrials'). \n",
    "#The RNN training process is followed carefully in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b49eccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.ndimage.filters\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from charSeqRNN import charSeqRNN, getDefaultRNNArgs\n",
    "\n",
    "#point this towards the top level dataset directory\n",
    "rootDir = os.path.join(os.path.expanduser('~'), 'handwritingBCIData')\n",
    "\n",
    "#train an RNN using data from these specified sessions\n",
    "dataDirs = ['t5.2019.05.08','t5.2019.11.25','t5.2019.12.09','t5.2019.12.11','t5.2019.12.18',\n",
    "            't5.2019.12.20','t5.2020.01.06','t5.2020.01.08','t5.2020.01.13','t5.2020.01.15']\n",
    "\n",
    "#use this train/test partition \n",
    "cvPart = 'HeldOutTrials'\n",
    "\n",
    "#name of the directory where this RNN run will be saved\n",
    "rnnOutputDir = cvPart\n",
    "\n",
    "#all RNN runs are saved in 'Step4_RNNTraining'\n",
    "data_path = os.path.join(rootDir, 'RNNTrainingSteps', 'Step4_RNNTraining')\n",
    "if not os.path.isdir(data_path):\n",
    "    os.mkdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1c3eb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will use the default arguments specified here\n",
    "args = getDefaultRNNArgs()\n",
    "\n",
    "#Configure the arguments for a multi-day RNN (that will have a unique input layer for each day)\n",
    "for x in range(len(dataDirs)):\n",
    "    args['sentencesFile_'+str(x)] = rootDir+'Datasets/'+dataDirs[x]+'/sentences.mat'\n",
    "    args['singleLettersFile_'+str(x)] = rootDir+'Datasets/'+dataDirs[x]+'/singleLetters.mat'\n",
    "    args['labelsFile_'+str(x)] = rootDir+'RNNTrainingSteps/Step2_HMMLabels/'+cvPart+'/'+dataDirs[x]+'_timeSeriesLabels.mat'\n",
    "    args['syntheticDatasetDir_'+str(x)] = rootDir+'RNNTrainingSteps/Step3_SyntheticSentences/'+cvPart+'/'+dataDirs[x]+'_syntheticSentences/'\n",
    "    args['cvPartitionFile_'+str(x)] = rootDir+'RNNTrainingSteps/trainTestPartitions_'+cvPart+'.mat'\n",
    "    args['sessionName_'+str(x)] = dataDirs[x]\n",
    "    \n",
    "args['outputDir'] = os.path.join(data_path, rnnOutputDir)\n",
    "if not os.path.isdir(args['outputDir']):\n",
    "    os.mkdir(args['outputDir'])\n",
    "    \n",
    "#this weights each day equally (0.1 probability for each day) and allocates a unique input layer for each day (0-9)\n",
    "args['dayProbability'] = '[0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1]'\n",
    "args['dayToLayerMap'] = '[0,1,2,3,4,5,6,7,8,9]'\n",
    "\n",
    "#save the arguments dictionary so that the RNN program can load it\n",
    "pickle.dump( args, open(os.path.join(args['outputDir'], 'args.p'), \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b9d270f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting CUDA_VISIBLE_DEVICES to 0\n"
     ]
    }
   ],
   "source": [
    "argsFile = os.path.join(args['outputDir'], 'args.p')\n",
    "argDict = pickle.load(open(argsFile, \"rb\" ))\n",
    "\n",
    "#set the visible device to the gpu specified in 'args' (otherwise tensorflow will steal all the GPUs)\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "print('Setting CUDA_VISIBLE_DEVICES to ' + argDict['gpuNumber'])\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=argDict['gpuNumber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c968e468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188fa9ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe751757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabe343b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
